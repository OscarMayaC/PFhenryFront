{"ast":null,"code":"\"use strict\";\n\nvar __extends = this && this.__extends || function () {\n  var extendStatics = function (d, b) {\n    extendStatics = Object.setPrototypeOf || {\n      __proto__: []\n    } instanceof Array && function (d, b) {\n      d.__proto__ = b;\n    } || function (d, b) {\n      for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p];\n    };\n    return extendStatics(d, b);\n  };\n  return function (d, b) {\n    if (typeof b !== \"function\" && b !== null) throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\n    extendStatics(d, b);\n    function __() {\n      this.constructor = d;\n    }\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n  };\n}();\nvar __importDefault = this && this.__importDefault || function (mod) {\n  return mod && mod.__esModule ? mod : {\n    \"default\": mod\n  };\n};\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.attemptInRepetitionRecovery = exports.Recoverable = exports.InRuleRecoveryException = exports.IN_RULE_RECOVERY_EXCEPTION = exports.EOF_FOLLOW_KEY = void 0;\nvar tokens_public_1 = require(\"../../../scan/tokens_public\");\nvar isEmpty_1 = __importDefault(require(\"lodash/isEmpty\"));\nvar dropRight_1 = __importDefault(require(\"lodash/dropRight\"));\nvar flatten_1 = __importDefault(require(\"lodash/flatten\"));\nvar map_1 = __importDefault(require(\"lodash/map\"));\nvar find_1 = __importDefault(require(\"lodash/find\"));\nvar has_1 = __importDefault(require(\"lodash/has\"));\nvar includes_1 = __importDefault(require(\"lodash/includes\"));\nvar clone_1 = __importDefault(require(\"lodash/clone\"));\nvar exceptions_public_1 = require(\"../../exceptions_public\");\nvar constants_1 = require(\"../../constants\");\nvar parser_1 = require(\"../parser\");\nexports.EOF_FOLLOW_KEY = {};\nexports.IN_RULE_RECOVERY_EXCEPTION = \"InRuleRecoveryException\";\nvar InRuleRecoveryException = /** @class */function (_super) {\n  __extends(InRuleRecoveryException, _super);\n  function InRuleRecoveryException(message) {\n    var _this = _super.call(this, message) || this;\n    _this.name = exports.IN_RULE_RECOVERY_EXCEPTION;\n    return _this;\n  }\n  return InRuleRecoveryException;\n}(Error);\nexports.InRuleRecoveryException = InRuleRecoveryException;\n/**\n * This trait is responsible for the error recovery and fault tolerant logic\n */\nvar Recoverable = /** @class */function () {\n  function Recoverable() {}\n  Recoverable.prototype.initRecoverable = function (config) {\n    this.firstAfterRepMap = {};\n    this.resyncFollows = {};\n    this.recoveryEnabled = (0, has_1.default)(config, \"recoveryEnabled\") ? config.recoveryEnabled // assumes end user provides the correct config value/type\n    : parser_1.DEFAULT_PARSER_CONFIG.recoveryEnabled;\n    // performance optimization, NOOP will be inlined which\n    // effectively means that this optional feature does not exist\n    // when not used.\n    if (this.recoveryEnabled) {\n      this.attemptInRepetitionRecovery = attemptInRepetitionRecovery;\n    }\n  };\n  Recoverable.prototype.getTokenToInsert = function (tokType) {\n    var tokToInsert = (0, tokens_public_1.createTokenInstance)(tokType, \"\", NaN, NaN, NaN, NaN, NaN, NaN);\n    tokToInsert.isInsertedInRecovery = true;\n    return tokToInsert;\n  };\n  Recoverable.prototype.canTokenTypeBeInsertedInRecovery = function (tokType) {\n    return true;\n  };\n  Recoverable.prototype.canTokenTypeBeDeletedInRecovery = function (tokType) {\n    return true;\n  };\n  Recoverable.prototype.tryInRepetitionRecovery = function (grammarRule, grammarRuleArgs, lookAheadFunc, expectedTokType) {\n    var _this = this;\n    // TODO: can the resyncTokenType be cached?\n    var reSyncTokType = this.findReSyncTokenType();\n    var savedLexerState = this.exportLexerState();\n    var resyncedTokens = [];\n    var passedResyncPoint = false;\n    var nextTokenWithoutResync = this.LA(1);\n    var currToken = this.LA(1);\n    var generateErrorMessage = function () {\n      var previousToken = _this.LA(0);\n      // we are preemptively re-syncing before an error has been detected, therefor we must reproduce\n      // the error that would have been thrown\n      var msg = _this.errorMessageProvider.buildMismatchTokenMessage({\n        expected: expectedTokType,\n        actual: nextTokenWithoutResync,\n        previous: previousToken,\n        ruleName: _this.getCurrRuleFullName()\n      });\n      var error = new exceptions_public_1.MismatchedTokenException(msg, nextTokenWithoutResync, _this.LA(0));\n      // the first token here will be the original cause of the error, this is not part of the resyncedTokens property.\n      error.resyncedTokens = (0, dropRight_1.default)(resyncedTokens);\n      _this.SAVE_ERROR(error);\n    };\n    while (!passedResyncPoint) {\n      // re-synced to a point where we can safely exit the repetition/\n      if (this.tokenMatcher(currToken, expectedTokType)) {\n        generateErrorMessage();\n        return; // must return here to avoid reverting the inputIdx\n      } else if (lookAheadFunc.call(this)) {\n        // we skipped enough tokens so we can resync right back into another iteration of the repetition grammar rule\n        generateErrorMessage();\n        // recursive invocation in other to support multiple re-syncs in the same top level repetition grammar rule\n        grammarRule.apply(this, grammarRuleArgs);\n        return; // must return here to avoid reverting the inputIdx\n      } else if (this.tokenMatcher(currToken, reSyncTokType)) {\n        passedResyncPoint = true;\n      } else {\n        currToken = this.SKIP_TOKEN();\n        this.addToResyncTokens(currToken, resyncedTokens);\n      }\n    }\n    // we were unable to find a CLOSER point to resync inside the Repetition, reset the state.\n    // The parsing exception we were trying to prevent will happen in the NEXT parsing step. it may be handled by\n    // \"between rules\" resync recovery later in the flow.\n    this.importLexerState(savedLexerState);\n  };\n  Recoverable.prototype.shouldInRepetitionRecoveryBeTried = function (expectTokAfterLastMatch, nextTokIdx, notStuck) {\n    // Edge case of arriving from a MANY repetition which is stuck\n    // Attempting recovery in this case could cause an infinite loop\n    if (notStuck === false) {\n      return false;\n    }\n    // no need to recover, next token is what we expect...\n    if (this.tokenMatcher(this.LA(1), expectTokAfterLastMatch)) {\n      return false;\n    }\n    // error recovery is disabled during backtracking as it can make the parser ignore a valid grammar path\n    // and prefer some backtracking path that includes recovered errors.\n    if (this.isBackTracking()) {\n      return false;\n    }\n    // if we can perform inRule recovery (single token insertion or deletion) we always prefer that recovery algorithm\n    // because if it works, it makes the least amount of changes to the input stream (greedy algorithm)\n    //noinspection RedundantIfStatementJS\n    if (this.canPerformInRuleRecovery(expectTokAfterLastMatch, this.getFollowsForInRuleRecovery(expectTokAfterLastMatch, nextTokIdx))) {\n      return false;\n    }\n    return true;\n  };\n  // Error Recovery functionality\n  Recoverable.prototype.getFollowsForInRuleRecovery = function (tokType, tokIdxInRule) {\n    var grammarPath = this.getCurrentGrammarPath(tokType, tokIdxInRule);\n    var follows = this.getNextPossibleTokenTypes(grammarPath);\n    return follows;\n  };\n  Recoverable.prototype.tryInRuleRecovery = function (expectedTokType, follows) {\n    if (this.canRecoverWithSingleTokenInsertion(expectedTokType, follows)) {\n      var tokToInsert = this.getTokenToInsert(expectedTokType);\n      return tokToInsert;\n    }\n    if (this.canRecoverWithSingleTokenDeletion(expectedTokType)) {\n      var nextTok = this.SKIP_TOKEN();\n      this.consumeToken();\n      return nextTok;\n    }\n    throw new InRuleRecoveryException(\"sad sad panda\");\n  };\n  Recoverable.prototype.canPerformInRuleRecovery = function (expectedToken, follows) {\n    return this.canRecoverWithSingleTokenInsertion(expectedToken, follows) || this.canRecoverWithSingleTokenDeletion(expectedToken);\n  };\n  Recoverable.prototype.canRecoverWithSingleTokenInsertion = function (expectedTokType, follows) {\n    var _this = this;\n    if (!this.canTokenTypeBeInsertedInRecovery(expectedTokType)) {\n      return false;\n    }\n    // must know the possible following tokens to perform single token insertion\n    if ((0, isEmpty_1.default)(follows)) {\n      return false;\n    }\n    var mismatchedTok = this.LA(1);\n    var isMisMatchedTokInFollows = (0, find_1.default)(follows, function (possibleFollowsTokType) {\n      return _this.tokenMatcher(mismatchedTok, possibleFollowsTokType);\n    }) !== undefined;\n    return isMisMatchedTokInFollows;\n  };\n  Recoverable.prototype.canRecoverWithSingleTokenDeletion = function (expectedTokType) {\n    if (!this.canTokenTypeBeDeletedInRecovery(expectedTokType)) {\n      return false;\n    }\n    var isNextTokenWhatIsExpected = this.tokenMatcher(this.LA(2), expectedTokType);\n    return isNextTokenWhatIsExpected;\n  };\n  Recoverable.prototype.isInCurrentRuleReSyncSet = function (tokenTypeIdx) {\n    var followKey = this.getCurrFollowKey();\n    var currentRuleReSyncSet = this.getFollowSetFromFollowKey(followKey);\n    return (0, includes_1.default)(currentRuleReSyncSet, tokenTypeIdx);\n  };\n  Recoverable.prototype.findReSyncTokenType = function () {\n    var allPossibleReSyncTokTypes = this.flattenFollowSet();\n    // this loop will always terminate as EOF is always in the follow stack and also always (virtually) in the input\n    var nextToken = this.LA(1);\n    var k = 2;\n    while (true) {\n      var foundMatch = (0, find_1.default)(allPossibleReSyncTokTypes, function (resyncTokType) {\n        var canMatch = (0, tokens_public_1.tokenMatcher)(nextToken, resyncTokType);\n        return canMatch;\n      });\n      if (foundMatch !== undefined) {\n        return foundMatch;\n      }\n      nextToken = this.LA(k);\n      k++;\n    }\n  };\n  Recoverable.prototype.getCurrFollowKey = function () {\n    // the length is at least one as we always add the ruleName to the stack before invoking the rule.\n    if (this.RULE_STACK.length === 1) {\n      return exports.EOF_FOLLOW_KEY;\n    }\n    var currRuleShortName = this.getLastExplicitRuleShortName();\n    var currRuleIdx = this.getLastExplicitRuleOccurrenceIndex();\n    var prevRuleShortName = this.getPreviousExplicitRuleShortName();\n    return {\n      ruleName: this.shortRuleNameToFullName(currRuleShortName),\n      idxInCallingRule: currRuleIdx,\n      inRule: this.shortRuleNameToFullName(prevRuleShortName)\n    };\n  };\n  Recoverable.prototype.buildFullFollowKeyStack = function () {\n    var _this = this;\n    var explicitRuleStack = this.RULE_STACK;\n    var explicitOccurrenceStack = this.RULE_OCCURRENCE_STACK;\n    return (0, map_1.default)(explicitRuleStack, function (ruleName, idx) {\n      if (idx === 0) {\n        return exports.EOF_FOLLOW_KEY;\n      }\n      return {\n        ruleName: _this.shortRuleNameToFullName(ruleName),\n        idxInCallingRule: explicitOccurrenceStack[idx],\n        inRule: _this.shortRuleNameToFullName(explicitRuleStack[idx - 1])\n      };\n    });\n  };\n  Recoverable.prototype.flattenFollowSet = function () {\n    var _this = this;\n    var followStack = (0, map_1.default)(this.buildFullFollowKeyStack(), function (currKey) {\n      return _this.getFollowSetFromFollowKey(currKey);\n    });\n    return (0, flatten_1.default)(followStack);\n  };\n  Recoverable.prototype.getFollowSetFromFollowKey = function (followKey) {\n    if (followKey === exports.EOF_FOLLOW_KEY) {\n      return [tokens_public_1.EOF];\n    }\n    var followName = followKey.ruleName + followKey.idxInCallingRule + constants_1.IN + followKey.inRule;\n    return this.resyncFollows[followName];\n  };\n  // It does not make any sense to include a virtual EOF token in the list of resynced tokens\n  // as EOF does not really exist and thus does not contain any useful information (line/column numbers)\n  Recoverable.prototype.addToResyncTokens = function (token, resyncTokens) {\n    if (!this.tokenMatcher(token, tokens_public_1.EOF)) {\n      resyncTokens.push(token);\n    }\n    return resyncTokens;\n  };\n  Recoverable.prototype.reSyncTo = function (tokType) {\n    var resyncedTokens = [];\n    var nextTok = this.LA(1);\n    while (this.tokenMatcher(nextTok, tokType) === false) {\n      nextTok = this.SKIP_TOKEN();\n      this.addToResyncTokens(nextTok, resyncedTokens);\n    }\n    // the last token is not part of the error.\n    return (0, dropRight_1.default)(resyncedTokens);\n  };\n  Recoverable.prototype.attemptInRepetitionRecovery = function (prodFunc, args, lookaheadFunc, dslMethodIdx, prodOccurrence, nextToksWalker, notStuck) {\n    // by default this is a NO-OP\n    // The actual implementation is with the function(not method) below\n  };\n  Recoverable.prototype.getCurrentGrammarPath = function (tokType, tokIdxInRule) {\n    var pathRuleStack = this.getHumanReadableRuleStack();\n    var pathOccurrenceStack = (0, clone_1.default)(this.RULE_OCCURRENCE_STACK);\n    var grammarPath = {\n      ruleStack: pathRuleStack,\n      occurrenceStack: pathOccurrenceStack,\n      lastTok: tokType,\n      lastTokOccurrence: tokIdxInRule\n    };\n    return grammarPath;\n  };\n  Recoverable.prototype.getHumanReadableRuleStack = function () {\n    var _this = this;\n    return (0, map_1.default)(this.RULE_STACK, function (currShortName) {\n      return _this.shortRuleNameToFullName(currShortName);\n    });\n  };\n  return Recoverable;\n}();\nexports.Recoverable = Recoverable;\nfunction attemptInRepetitionRecovery(prodFunc, args, lookaheadFunc, dslMethodIdx, prodOccurrence, nextToksWalker, notStuck) {\n  var key = this.getKeyForAutomaticLookahead(dslMethodIdx, prodOccurrence);\n  var firstAfterRepInfo = this.firstAfterRepMap[key];\n  if (firstAfterRepInfo === undefined) {\n    var currRuleName = this.getCurrRuleFullName();\n    var ruleGrammar = this.getGAstProductions()[currRuleName];\n    var walker = new nextToksWalker(ruleGrammar, prodOccurrence);\n    firstAfterRepInfo = walker.startWalking();\n    this.firstAfterRepMap[key] = firstAfterRepInfo;\n  }\n  var expectTokAfterLastMatch = firstAfterRepInfo.token;\n  var nextTokIdx = firstAfterRepInfo.occurrence;\n  var isEndOfRule = firstAfterRepInfo.isEndOfRule;\n  // special edge case of a TOP most repetition after which the input should END.\n  // this will force an attempt for inRule recovery in that scenario.\n  if (this.RULE_STACK.length === 1 && isEndOfRule && expectTokAfterLastMatch === undefined) {\n    expectTokAfterLastMatch = tokens_public_1.EOF;\n    nextTokIdx = 1;\n  }\n  // We don't have anything to re-sync to...\n  // this condition was extracted from `shouldInRepetitionRecoveryBeTried` to act as a type-guard\n  if (expectTokAfterLastMatch === undefined || nextTokIdx === undefined) {\n    return;\n  }\n  if (this.shouldInRepetitionRecoveryBeTried(expectTokAfterLastMatch, nextTokIdx, notStuck)) {\n    // TODO: performance optimization: instead of passing the original args here, we modify\n    // the args param (or create a new one) and make sure the lookahead func is explicitly provided\n    // to avoid searching the cache for it once more.\n    this.tryInRepetitionRecovery(prodFunc, args, lookaheadFunc, expectTokAfterLastMatch);\n  }\n}\nexports.attemptInRepetitionRecovery = attemptInRepetitionRecovery;","map":{"version":3,"names":["tokens_public_1","require","isEmpty_1","__importDefault","dropRight_1","flatten_1","map_1","find_1","has_1","includes_1","clone_1","exceptions_public_1","constants_1","parser_1","exports","EOF_FOLLOW_KEY","IN_RULE_RECOVERY_EXCEPTION","InRuleRecoveryException","_super","__extends","message","_this","call","name","Error","Recoverable","prototype","initRecoverable","config","firstAfterRepMap","resyncFollows","recoveryEnabled","default","DEFAULT_PARSER_CONFIG","attemptInRepetitionRecovery","getTokenToInsert","tokType","tokToInsert","createTokenInstance","NaN","isInsertedInRecovery","canTokenTypeBeInsertedInRecovery","canTokenTypeBeDeletedInRecovery","tryInRepetitionRecovery","grammarRule","grammarRuleArgs","lookAheadFunc","expectedTokType","reSyncTokType","findReSyncTokenType","savedLexerState","exportLexerState","resyncedTokens","passedResyncPoint","nextTokenWithoutResync","LA","currToken","generateErrorMessage","previousToken","msg","errorMessageProvider","buildMismatchTokenMessage","expected","actual","previous","ruleName","getCurrRuleFullName","error","MismatchedTokenException","SAVE_ERROR","tokenMatcher","apply","SKIP_TOKEN","addToResyncTokens","importLexerState","shouldInRepetitionRecoveryBeTried","expectTokAfterLastMatch","nextTokIdx","notStuck","isBackTracking","canPerformInRuleRecovery","getFollowsForInRuleRecovery","tokIdxInRule","grammarPath","getCurrentGrammarPath","follows","getNextPossibleTokenTypes","tryInRuleRecovery","canRecoverWithSingleTokenInsertion","canRecoverWithSingleTokenDeletion","nextTok","consumeToken","expectedToken","mismatchedTok","isMisMatchedTokInFollows","possibleFollowsTokType","undefined","isNextTokenWhatIsExpected","isInCurrentRuleReSyncSet","tokenTypeIdx","followKey","getCurrFollowKey","currentRuleReSyncSet","getFollowSetFromFollowKey","allPossibleReSyncTokTypes","flattenFollowSet","nextToken","k","foundMatch","resyncTokType","canMatch","RULE_STACK","length","currRuleShortName","getLastExplicitRuleShortName","currRuleIdx","getLastExplicitRuleOccurrenceIndex","prevRuleShortName","getPreviousExplicitRuleShortName","shortRuleNameToFullName","idxInCallingRule","inRule","buildFullFollowKeyStack","explicitRuleStack","explicitOccurrenceStack","RULE_OCCURRENCE_STACK","idx","followStack","currKey","EOF","followName","IN","token","resyncTokens","push","reSyncTo","prodFunc","args","lookaheadFunc","dslMethodIdx","prodOccurrence","nextToksWalker","pathRuleStack","getHumanReadableRuleStack","pathOccurrenceStack","ruleStack","occurrenceStack","lastTok","lastTokOccurrence","currShortName","key","getKeyForAutomaticLookahead","firstAfterRepInfo","currRuleName","ruleGrammar","getGAstProductions","walker","startWalking","occurrence","isEndOfRule"],"sources":["/Users/rociopichardo/Desktop/PFhenryFront/restaurante-pf-front/node_modules/chevrotain/src/parse/parser/traits/recoverable.ts"],"sourcesContent":["import {\n  createTokenInstance,\n  EOF,\n  tokenMatcher\n} from \"../../../scan/tokens_public\"\nimport {\n  AbstractNextTerminalAfterProductionWalker,\n  IFirstAfterRepetition\n} from \"../../grammar/interpreter\"\nimport isEmpty from \"lodash/isEmpty\"\nimport dropRight from \"lodash/dropRight\"\nimport flatten from \"lodash/flatten\"\nimport map from \"lodash/map\"\nimport find from \"lodash/find\"\nimport has from \"lodash/has\"\nimport includes from \"lodash/includes\"\nimport clone from \"lodash/clone\"\nimport {\n  IParserConfig,\n  IToken,\n  ITokenGrammarPath,\n  TokenType\n} from \"@chevrotain/types\"\nimport { MismatchedTokenException } from \"../../exceptions_public\"\nimport { IN } from \"../../constants\"\nimport { MixedInParser } from \"./parser_traits\"\nimport { DEFAULT_PARSER_CONFIG } from \"../parser\"\n\nexport const EOF_FOLLOW_KEY: any = {}\n\nexport interface IFollowKey {\n  ruleName: string\n  idxInCallingRule: number\n  inRule: string\n}\n\nexport const IN_RULE_RECOVERY_EXCEPTION = \"InRuleRecoveryException\"\n\nexport class InRuleRecoveryException extends Error {\n  constructor(message: string) {\n    super(message)\n    this.name = IN_RULE_RECOVERY_EXCEPTION\n  }\n}\n\n/**\n * This trait is responsible for the error recovery and fault tolerant logic\n */\nexport class Recoverable {\n  recoveryEnabled: boolean\n  firstAfterRepMap: Record<string, IFirstAfterRepetition>\n  resyncFollows: Record<string, TokenType[]>\n\n  initRecoverable(config: IParserConfig) {\n    this.firstAfterRepMap = {}\n    this.resyncFollows = {}\n\n    this.recoveryEnabled = has(config, \"recoveryEnabled\")\n      ? (config.recoveryEnabled as boolean) // assumes end user provides the correct config value/type\n      : DEFAULT_PARSER_CONFIG.recoveryEnabled\n\n    // performance optimization, NOOP will be inlined which\n    // effectively means that this optional feature does not exist\n    // when not used.\n    if (this.recoveryEnabled) {\n      this.attemptInRepetitionRecovery = attemptInRepetitionRecovery\n    }\n  }\n\n  public getTokenToInsert(tokType: TokenType): IToken {\n    const tokToInsert = createTokenInstance(\n      tokType,\n      \"\",\n      NaN,\n      NaN,\n      NaN,\n      NaN,\n      NaN,\n      NaN\n    )\n    tokToInsert.isInsertedInRecovery = true\n    return tokToInsert\n  }\n\n  public canTokenTypeBeInsertedInRecovery(tokType: TokenType): boolean {\n    return true\n  }\n\n  public canTokenTypeBeDeletedInRecovery(tokType: TokenType): boolean {\n    return true\n  }\n\n  tryInRepetitionRecovery(\n    this: MixedInParser,\n    grammarRule: Function,\n    grammarRuleArgs: any[],\n    lookAheadFunc: () => boolean,\n    expectedTokType: TokenType\n  ): void {\n    // TODO: can the resyncTokenType be cached?\n    const reSyncTokType = this.findReSyncTokenType()\n    const savedLexerState = this.exportLexerState()\n    const resyncedTokens: IToken[] = []\n    let passedResyncPoint = false\n\n    const nextTokenWithoutResync = this.LA(1)\n    let currToken = this.LA(1)\n\n    const generateErrorMessage = () => {\n      const previousToken = this.LA(0)\n      // we are preemptively re-syncing before an error has been detected, therefor we must reproduce\n      // the error that would have been thrown\n      const msg = this.errorMessageProvider.buildMismatchTokenMessage({\n        expected: expectedTokType,\n        actual: nextTokenWithoutResync,\n        previous: previousToken,\n        ruleName: this.getCurrRuleFullName()\n      })\n      const error = new MismatchedTokenException(\n        msg,\n        nextTokenWithoutResync,\n        this.LA(0)\n      )\n      // the first token here will be the original cause of the error, this is not part of the resyncedTokens property.\n      error.resyncedTokens = dropRight(resyncedTokens)\n      this.SAVE_ERROR(error)\n    }\n\n    while (!passedResyncPoint) {\n      // re-synced to a point where we can safely exit the repetition/\n      if (this.tokenMatcher(currToken, expectedTokType)) {\n        generateErrorMessage()\n        return // must return here to avoid reverting the inputIdx\n      } else if (lookAheadFunc.call(this)) {\n        // we skipped enough tokens so we can resync right back into another iteration of the repetition grammar rule\n        generateErrorMessage()\n        // recursive invocation in other to support multiple re-syncs in the same top level repetition grammar rule\n        grammarRule.apply(this, grammarRuleArgs)\n        return // must return here to avoid reverting the inputIdx\n      } else if (this.tokenMatcher(currToken, reSyncTokType)) {\n        passedResyncPoint = true\n      } else {\n        currToken = this.SKIP_TOKEN()\n        this.addToResyncTokens(currToken, resyncedTokens)\n      }\n    }\n\n    // we were unable to find a CLOSER point to resync inside the Repetition, reset the state.\n    // The parsing exception we were trying to prevent will happen in the NEXT parsing step. it may be handled by\n    // \"between rules\" resync recovery later in the flow.\n    this.importLexerState(savedLexerState)\n  }\n\n  shouldInRepetitionRecoveryBeTried(\n    this: MixedInParser,\n    expectTokAfterLastMatch: TokenType,\n    nextTokIdx: number,\n    notStuck: boolean | undefined\n  ): boolean {\n    // Edge case of arriving from a MANY repetition which is stuck\n    // Attempting recovery in this case could cause an infinite loop\n    if (notStuck === false) {\n      return false\n    }\n\n    // no need to recover, next token is what we expect...\n    if (this.tokenMatcher(this.LA(1), expectTokAfterLastMatch)) {\n      return false\n    }\n\n    // error recovery is disabled during backtracking as it can make the parser ignore a valid grammar path\n    // and prefer some backtracking path that includes recovered errors.\n    if (this.isBackTracking()) {\n      return false\n    }\n\n    // if we can perform inRule recovery (single token insertion or deletion) we always prefer that recovery algorithm\n    // because if it works, it makes the least amount of changes to the input stream (greedy algorithm)\n    //noinspection RedundantIfStatementJS\n    if (\n      this.canPerformInRuleRecovery(\n        expectTokAfterLastMatch,\n        this.getFollowsForInRuleRecovery(expectTokAfterLastMatch, nextTokIdx)\n      )\n    ) {\n      return false\n    }\n\n    return true\n  }\n\n  // Error Recovery functionality\n  getFollowsForInRuleRecovery(\n    this: MixedInParser,\n    tokType: TokenType,\n    tokIdxInRule: number\n  ): TokenType[] {\n    const grammarPath = this.getCurrentGrammarPath(tokType, tokIdxInRule)\n    const follows = this.getNextPossibleTokenTypes(grammarPath)\n    return follows\n  }\n\n  tryInRuleRecovery(\n    this: MixedInParser,\n    expectedTokType: TokenType,\n    follows: TokenType[]\n  ): IToken {\n    if (this.canRecoverWithSingleTokenInsertion(expectedTokType, follows)) {\n      const tokToInsert = this.getTokenToInsert(expectedTokType)\n      return tokToInsert\n    }\n\n    if (this.canRecoverWithSingleTokenDeletion(expectedTokType)) {\n      const nextTok = this.SKIP_TOKEN()\n      this.consumeToken()\n      return nextTok\n    }\n\n    throw new InRuleRecoveryException(\"sad sad panda\")\n  }\n\n  canPerformInRuleRecovery(\n    this: MixedInParser,\n    expectedToken: TokenType,\n    follows: TokenType[]\n  ): boolean {\n    return (\n      this.canRecoverWithSingleTokenInsertion(expectedToken, follows) ||\n      this.canRecoverWithSingleTokenDeletion(expectedToken)\n    )\n  }\n\n  canRecoverWithSingleTokenInsertion(\n    this: MixedInParser,\n    expectedTokType: TokenType,\n    follows: TokenType[]\n  ): boolean {\n    if (!this.canTokenTypeBeInsertedInRecovery(expectedTokType)) {\n      return false\n    }\n\n    // must know the possible following tokens to perform single token insertion\n    if (isEmpty(follows)) {\n      return false\n    }\n\n    const mismatchedTok = this.LA(1)\n    const isMisMatchedTokInFollows =\n      find(follows, (possibleFollowsTokType: TokenType) => {\n        return this.tokenMatcher(mismatchedTok, possibleFollowsTokType)\n      }) !== undefined\n\n    return isMisMatchedTokInFollows\n  }\n\n  canRecoverWithSingleTokenDeletion(\n    this: MixedInParser,\n    expectedTokType: TokenType\n  ): boolean {\n    if (!this.canTokenTypeBeDeletedInRecovery(expectedTokType)) {\n      return false\n    }\n\n    const isNextTokenWhatIsExpected = this.tokenMatcher(\n      this.LA(2),\n      expectedTokType\n    )\n    return isNextTokenWhatIsExpected\n  }\n\n  isInCurrentRuleReSyncSet(\n    this: MixedInParser,\n    tokenTypeIdx: TokenType\n  ): boolean {\n    const followKey = this.getCurrFollowKey()\n    const currentRuleReSyncSet = this.getFollowSetFromFollowKey(followKey)\n    return includes(currentRuleReSyncSet, tokenTypeIdx)\n  }\n\n  findReSyncTokenType(this: MixedInParser): TokenType {\n    const allPossibleReSyncTokTypes = this.flattenFollowSet()\n    // this loop will always terminate as EOF is always in the follow stack and also always (virtually) in the input\n    let nextToken = this.LA(1)\n    let k = 2\n    while (true) {\n      const foundMatch = find(allPossibleReSyncTokTypes, (resyncTokType) => {\n        const canMatch = tokenMatcher(nextToken, resyncTokType)\n        return canMatch\n      })\n      if (foundMatch !== undefined) {\n        return foundMatch\n      }\n      nextToken = this.LA(k)\n      k++\n    }\n  }\n\n  getCurrFollowKey(this: MixedInParser): IFollowKey {\n    // the length is at least one as we always add the ruleName to the stack before invoking the rule.\n    if (this.RULE_STACK.length === 1) {\n      return EOF_FOLLOW_KEY\n    }\n    const currRuleShortName = this.getLastExplicitRuleShortName()\n    const currRuleIdx = this.getLastExplicitRuleOccurrenceIndex()\n    const prevRuleShortName = this.getPreviousExplicitRuleShortName()\n\n    return {\n      ruleName: this.shortRuleNameToFullName(currRuleShortName),\n      idxInCallingRule: currRuleIdx,\n      inRule: this.shortRuleNameToFullName(prevRuleShortName)\n    }\n  }\n\n  buildFullFollowKeyStack(this: MixedInParser): IFollowKey[] {\n    const explicitRuleStack = this.RULE_STACK\n    const explicitOccurrenceStack = this.RULE_OCCURRENCE_STACK\n\n    return map(explicitRuleStack, (ruleName, idx) => {\n      if (idx === 0) {\n        return EOF_FOLLOW_KEY\n      }\n      return {\n        ruleName: this.shortRuleNameToFullName(ruleName),\n        idxInCallingRule: explicitOccurrenceStack[idx],\n        inRule: this.shortRuleNameToFullName(explicitRuleStack[idx - 1])\n      }\n    })\n  }\n\n  flattenFollowSet(this: MixedInParser): TokenType[] {\n    const followStack = map(this.buildFullFollowKeyStack(), (currKey) => {\n      return this.getFollowSetFromFollowKey(currKey)\n    })\n    return <any>flatten(followStack)\n  }\n\n  getFollowSetFromFollowKey(\n    this: MixedInParser,\n    followKey: IFollowKey\n  ): TokenType[] {\n    if (followKey === EOF_FOLLOW_KEY) {\n      return [EOF]\n    }\n\n    const followName =\n      followKey.ruleName + followKey.idxInCallingRule + IN + followKey.inRule\n\n    return this.resyncFollows[followName]\n  }\n\n  // It does not make any sense to include a virtual EOF token in the list of resynced tokens\n  // as EOF does not really exist and thus does not contain any useful information (line/column numbers)\n  addToResyncTokens(\n    this: MixedInParser,\n    token: IToken,\n    resyncTokens: IToken[]\n  ): IToken[] {\n    if (!this.tokenMatcher(token, EOF)) {\n      resyncTokens.push(token)\n    }\n    return resyncTokens\n  }\n\n  reSyncTo(this: MixedInParser, tokType: TokenType): IToken[] {\n    const resyncedTokens: IToken[] = []\n    let nextTok = this.LA(1)\n    while (this.tokenMatcher(nextTok, tokType) === false) {\n      nextTok = this.SKIP_TOKEN()\n      this.addToResyncTokens(nextTok, resyncedTokens)\n    }\n    // the last token is not part of the error.\n    return dropRight(resyncedTokens)\n  }\n\n  attemptInRepetitionRecovery(\n    this: MixedInParser,\n    prodFunc: Function,\n    args: any[],\n    lookaheadFunc: () => boolean,\n    dslMethodIdx: number,\n    prodOccurrence: number,\n    nextToksWalker: typeof AbstractNextTerminalAfterProductionWalker,\n    notStuck?: boolean\n  ): void {\n    // by default this is a NO-OP\n    // The actual implementation is with the function(not method) below\n  }\n\n  getCurrentGrammarPath(\n    this: MixedInParser,\n    tokType: TokenType,\n    tokIdxInRule: number\n  ): ITokenGrammarPath {\n    const pathRuleStack: string[] = this.getHumanReadableRuleStack()\n    const pathOccurrenceStack: number[] = clone(this.RULE_OCCURRENCE_STACK)\n    const grammarPath: any = {\n      ruleStack: pathRuleStack,\n      occurrenceStack: pathOccurrenceStack,\n      lastTok: tokType,\n      lastTokOccurrence: tokIdxInRule\n    }\n\n    return grammarPath\n  }\n  getHumanReadableRuleStack(this: MixedInParser): string[] {\n    return map(this.RULE_STACK, (currShortName) =>\n      this.shortRuleNameToFullName(currShortName)\n    )\n  }\n}\n\nexport function attemptInRepetitionRecovery(\n  this: MixedInParser,\n  prodFunc: Function,\n  args: any[],\n  lookaheadFunc: () => boolean,\n  dslMethodIdx: number,\n  prodOccurrence: number,\n  nextToksWalker: typeof AbstractNextTerminalAfterProductionWalker,\n  notStuck?: boolean\n): void {\n  const key = this.getKeyForAutomaticLookahead(dslMethodIdx, prodOccurrence)\n  let firstAfterRepInfo = this.firstAfterRepMap[key]\n  if (firstAfterRepInfo === undefined) {\n    const currRuleName = this.getCurrRuleFullName()\n    const ruleGrammar = this.getGAstProductions()[currRuleName]\n    const walker: AbstractNextTerminalAfterProductionWalker =\n      new nextToksWalker(ruleGrammar, prodOccurrence)\n    firstAfterRepInfo = walker.startWalking()\n    this.firstAfterRepMap[key] = firstAfterRepInfo\n  }\n\n  let expectTokAfterLastMatch = firstAfterRepInfo.token\n  let nextTokIdx = firstAfterRepInfo.occurrence\n  const isEndOfRule = firstAfterRepInfo.isEndOfRule\n\n  // special edge case of a TOP most repetition after which the input should END.\n  // this will force an attempt for inRule recovery in that scenario.\n  if (\n    this.RULE_STACK.length === 1 &&\n    isEndOfRule &&\n    expectTokAfterLastMatch === undefined\n  ) {\n    expectTokAfterLastMatch = EOF\n    nextTokIdx = 1\n  }\n\n  // We don't have anything to re-sync to...\n  // this condition was extracted from `shouldInRepetitionRecoveryBeTried` to act as a type-guard\n  if (expectTokAfterLastMatch === undefined || nextTokIdx === undefined) {\n    return\n  }\n\n  if (\n    this.shouldInRepetitionRecoveryBeTried(\n      expectTokAfterLastMatch,\n      nextTokIdx,\n      notStuck\n    )\n  ) {\n    // TODO: performance optimization: instead of passing the original args here, we modify\n    // the args param (or create a new one) and make sure the lookahead func is explicitly provided\n    // to avoid searching the cache for it once more.\n    this.tryInRepetitionRecovery(\n      prodFunc,\n      args,\n      lookaheadFunc,\n      expectTokAfterLastMatch\n    )\n  }\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA,IAAAA,eAAA,GAAAC,OAAA;AASA,IAAAC,SAAA,GAAAC,eAAA,CAAAF,OAAA;AACA,IAAAG,WAAA,GAAAD,eAAA,CAAAF,OAAA;AACA,IAAAI,SAAA,GAAAF,eAAA,CAAAF,OAAA;AACA,IAAAK,KAAA,GAAAH,eAAA,CAAAF,OAAA;AACA,IAAAM,MAAA,GAAAJ,eAAA,CAAAF,OAAA;AACA,IAAAO,KAAA,GAAAL,eAAA,CAAAF,OAAA;AACA,IAAAQ,UAAA,GAAAN,eAAA,CAAAF,OAAA;AACA,IAAAS,OAAA,GAAAP,eAAA,CAAAF,OAAA;AAOA,IAAAU,mBAAA,GAAAV,OAAA;AACA,IAAAW,WAAA,GAAAX,OAAA;AAEA,IAAAY,QAAA,GAAAZ,OAAA;AAEaa,OAAA,CAAAC,cAAc,GAAQ,EAAE;AAQxBD,OAAA,CAAAE,0BAA0B,GAAG,yBAAyB;AAEnE,IAAAC,uBAAA,0BAAAC,MAAA;EAA6CC,SAAA,CAAAF,uBAAA,EAAAC,MAAA;EAC3C,SAAAD,wBAAYG,OAAe;IAA3B,IAAAC,KAAA,GACEH,MAAA,CAAAI,IAAA,OAAMF,OAAO,CAAC;IACdC,KAAI,CAACE,IAAI,GAAGT,OAAA,CAAAE,0BAA0B;;EACxC;EACF,OAAAC,uBAAC;AAAD,CAAC,CAL4CO,KAAK;AAArCV,OAAA,CAAAG,uBAAA,GAAAA,uBAAA;AAOb;;;AAGA,IAAAQ,WAAA;EAAA,SAAAA,YAAA,GAyWA;EApWEA,WAAA,CAAAC,SAAA,CAAAC,eAAe,GAAf,UAAgBC,MAAqB;IACnC,IAAI,CAACC,gBAAgB,GAAG,EAAE;IAC1B,IAAI,CAACC,aAAa,GAAG,EAAE;IAEvB,IAAI,CAACC,eAAe,GAAG,IAAAvB,KAAA,CAAAwB,OAAG,EAACJ,MAAM,EAAE,iBAAiB,CAAC,GAChDA,MAAM,CAACG,eAA2B,CAAC;IAAA,EACpClB,QAAA,CAAAoB,qBAAqB,CAACF,eAAe;IAEzC;IACA;IACA;IACA,IAAI,IAAI,CAACA,eAAe,EAAE;MACxB,IAAI,CAACG,2BAA2B,GAAGA,2BAA2B;;EAElE,CAAC;EAEMT,WAAA,CAAAC,SAAA,CAAAS,gBAAgB,GAAvB,UAAwBC,OAAkB;IACxC,IAAMC,WAAW,GAAG,IAAArC,eAAA,CAAAsC,mBAAmB,EACrCF,OAAO,EACP,EAAE,EACFG,GAAG,EACHA,GAAG,EACHA,GAAG,EACHA,GAAG,EACHA,GAAG,EACHA,GAAG,CACJ;IACDF,WAAW,CAACG,oBAAoB,GAAG,IAAI;IACvC,OAAOH,WAAW;EACpB,CAAC;EAEMZ,WAAA,CAAAC,SAAA,CAAAe,gCAAgC,GAAvC,UAAwCL,OAAkB;IACxD,OAAO,IAAI;EACb,CAAC;EAEMX,WAAA,CAAAC,SAAA,CAAAgB,+BAA+B,GAAtC,UAAuCN,OAAkB;IACvD,OAAO,IAAI;EACb,CAAC;EAEDX,WAAA,CAAAC,SAAA,CAAAiB,uBAAuB,GAAvB,UAEEC,WAAqB,EACrBC,eAAsB,EACtBC,aAA4B,EAC5BC,eAA0B;IAL5B,IAAA1B,KAAA;IAOE;IACA,IAAM2B,aAAa,GAAG,IAAI,CAACC,mBAAmB,EAAE;IAChD,IAAMC,eAAe,GAAG,IAAI,CAACC,gBAAgB,EAAE;IAC/C,IAAMC,cAAc,GAAa,EAAE;IACnC,IAAIC,iBAAiB,GAAG,KAAK;IAE7B,IAAMC,sBAAsB,GAAG,IAAI,CAACC,EAAE,CAAC,CAAC,CAAC;IACzC,IAAIC,SAAS,GAAG,IAAI,CAACD,EAAE,CAAC,CAAC,CAAC;IAE1B,IAAME,oBAAoB,GAAG,SAAAA,CAAA;MAC3B,IAAMC,aAAa,GAAGrC,KAAI,CAACkC,EAAE,CAAC,CAAC,CAAC;MAChC;MACA;MACA,IAAMI,GAAG,GAAGtC,KAAI,CAACuC,oBAAoB,CAACC,yBAAyB,CAAC;QAC9DC,QAAQ,EAAEf,eAAe;QACzBgB,MAAM,EAAET,sBAAsB;QAC9BU,QAAQ,EAAEN,aAAa;QACvBO,QAAQ,EAAE5C,KAAI,CAAC6C,mBAAmB;OACnC,CAAC;MACF,IAAMC,KAAK,GAAG,IAAIxD,mBAAA,CAAAyD,wBAAwB,CACxCT,GAAG,EACHL,sBAAsB,EACtBjC,KAAI,CAACkC,EAAE,CAAC,CAAC,CAAC,CACX;MACD;MACAY,KAAK,CAACf,cAAc,GAAG,IAAAhD,WAAA,CAAA4B,OAAS,EAACoB,cAAc,CAAC;MAChD/B,KAAI,CAACgD,UAAU,CAACF,KAAK,CAAC;IACxB,CAAC;IAED,OAAO,CAACd,iBAAiB,EAAE;MACzB;MACA,IAAI,IAAI,CAACiB,YAAY,CAACd,SAAS,EAAET,eAAe,CAAC,EAAE;QACjDU,oBAAoB,EAAE;QACtB,OAAM,CAAC;OACR,MAAM,IAAIX,aAAa,CAACxB,IAAI,CAAC,IAAI,CAAC,EAAE;QACnC;QACAmC,oBAAoB,EAAE;QACtB;QACAb,WAAW,CAAC2B,KAAK,CAAC,IAAI,EAAE1B,eAAe,CAAC;QACxC,OAAM,CAAC;OACR,MAAM,IAAI,IAAI,CAACyB,YAAY,CAACd,SAAS,EAAER,aAAa,CAAC,EAAE;QACtDK,iBAAiB,GAAG,IAAI;OACzB,MAAM;QACLG,SAAS,GAAG,IAAI,CAACgB,UAAU,EAAE;QAC7B,IAAI,CAACC,iBAAiB,CAACjB,SAAS,EAAEJ,cAAc,CAAC;;;IAIrD;IACA;IACA;IACA,IAAI,CAACsB,gBAAgB,CAACxB,eAAe,CAAC;EACxC,CAAC;EAEDzB,WAAA,CAAAC,SAAA,CAAAiD,iCAAiC,GAAjC,UAEEC,uBAAkC,EAClCC,UAAkB,EAClBC,QAA6B;IAE7B;IACA;IACA,IAAIA,QAAQ,KAAK,KAAK,EAAE;MACtB,OAAO,KAAK;;IAGd;IACA,IAAI,IAAI,CAACR,YAAY,CAAC,IAAI,CAACf,EAAE,CAAC,CAAC,CAAC,EAAEqB,uBAAuB,CAAC,EAAE;MAC1D,OAAO,KAAK;;IAGd;IACA;IACA,IAAI,IAAI,CAACG,cAAc,EAAE,EAAE;MACzB,OAAO,KAAK;;IAGd;IACA;IACA;IACA,IACE,IAAI,CAACC,wBAAwB,CAC3BJ,uBAAuB,EACvB,IAAI,CAACK,2BAA2B,CAACL,uBAAuB,EAAEC,UAAU,CAAC,CACtE,EACD;MACA,OAAO,KAAK;;IAGd,OAAO,IAAI;EACb,CAAC;EAED;EACApD,WAAA,CAAAC,SAAA,CAAAuD,2BAA2B,GAA3B,UAEE7C,OAAkB,EAClB8C,YAAoB;IAEpB,IAAMC,WAAW,GAAG,IAAI,CAACC,qBAAqB,CAAChD,OAAO,EAAE8C,YAAY,CAAC;IACrE,IAAMG,OAAO,GAAG,IAAI,CAACC,yBAAyB,CAACH,WAAW,CAAC;IAC3D,OAAOE,OAAO;EAChB,CAAC;EAED5D,WAAA,CAAAC,SAAA,CAAA6D,iBAAiB,GAAjB,UAEExC,eAA0B,EAC1BsC,OAAoB;IAEpB,IAAI,IAAI,CAACG,kCAAkC,CAACzC,eAAe,EAAEsC,OAAO,CAAC,EAAE;MACrE,IAAMhD,WAAW,GAAG,IAAI,CAACF,gBAAgB,CAACY,eAAe,CAAC;MAC1D,OAAOV,WAAW;;IAGpB,IAAI,IAAI,CAACoD,iCAAiC,CAAC1C,eAAe,CAAC,EAAE;MAC3D,IAAM2C,OAAO,GAAG,IAAI,CAAClB,UAAU,EAAE;MACjC,IAAI,CAACmB,YAAY,EAAE;MACnB,OAAOD,OAAO;;IAGhB,MAAM,IAAIzE,uBAAuB,CAAC,eAAe,CAAC;EACpD,CAAC;EAEDQ,WAAA,CAAAC,SAAA,CAAAsD,wBAAwB,GAAxB,UAEEY,aAAwB,EACxBP,OAAoB;IAEpB,OACE,IAAI,CAACG,kCAAkC,CAACI,aAAa,EAAEP,OAAO,CAAC,IAC/D,IAAI,CAACI,iCAAiC,CAACG,aAAa,CAAC;EAEzD,CAAC;EAEDnE,WAAA,CAAAC,SAAA,CAAA8D,kCAAkC,GAAlC,UAEEzC,eAA0B,EAC1BsC,OAAoB;IAHtB,IAAAhE,KAAA;IAKE,IAAI,CAAC,IAAI,CAACoB,gCAAgC,CAACM,eAAe,CAAC,EAAE;MAC3D,OAAO,KAAK;;IAGd;IACA,IAAI,IAAA7C,SAAA,CAAA8B,OAAO,EAACqD,OAAO,CAAC,EAAE;MACpB,OAAO,KAAK;;IAGd,IAAMQ,aAAa,GAAG,IAAI,CAACtC,EAAE,CAAC,CAAC,CAAC;IAChC,IAAMuC,wBAAwB,GAC5B,IAAAvF,MAAA,CAAAyB,OAAI,EAACqD,OAAO,EAAE,UAACU,sBAAiC;MAC9C,OAAO1E,KAAI,CAACiD,YAAY,CAACuB,aAAa,EAAEE,sBAAsB,CAAC;IACjE,CAAC,CAAC,KAAKC,SAAS;IAElB,OAAOF,wBAAwB;EACjC,CAAC;EAEDrE,WAAA,CAAAC,SAAA,CAAA+D,iCAAiC,GAAjC,UAEE1C,eAA0B;IAE1B,IAAI,CAAC,IAAI,CAACL,+BAA+B,CAACK,eAAe,CAAC,EAAE;MAC1D,OAAO,KAAK;;IAGd,IAAMkD,yBAAyB,GAAG,IAAI,CAAC3B,YAAY,CACjD,IAAI,CAACf,EAAE,CAAC,CAAC,CAAC,EACVR,eAAe,CAChB;IACD,OAAOkD,yBAAyB;EAClC,CAAC;EAEDxE,WAAA,CAAAC,SAAA,CAAAwE,wBAAwB,GAAxB,UAEEC,YAAuB;IAEvB,IAAMC,SAAS,GAAG,IAAI,CAACC,gBAAgB,EAAE;IACzC,IAAMC,oBAAoB,GAAG,IAAI,CAACC,yBAAyB,CAACH,SAAS,CAAC;IACtE,OAAO,IAAA3F,UAAA,CAAAuB,OAAQ,EAACsE,oBAAoB,EAAEH,YAAY,CAAC;EACrD,CAAC;EAED1E,WAAA,CAAAC,SAAA,CAAAuB,mBAAmB,GAAnB;IACE,IAAMuD,yBAAyB,GAAG,IAAI,CAACC,gBAAgB,EAAE;IACzD;IACA,IAAIC,SAAS,GAAG,IAAI,CAACnD,EAAE,CAAC,CAAC,CAAC;IAC1B,IAAIoD,CAAC,GAAG,CAAC;IACT,OAAO,IAAI,EAAE;MACX,IAAMC,UAAU,GAAG,IAAArG,MAAA,CAAAyB,OAAI,EAACwE,yBAAyB,EAAE,UAACK,aAAa;QAC/D,IAAMC,QAAQ,GAAG,IAAA9G,eAAA,CAAAsE,YAAY,EAACoC,SAAS,EAAEG,aAAa,CAAC;QACvD,OAAOC,QAAQ;MACjB,CAAC,CAAC;MACF,IAAIF,UAAU,KAAKZ,SAAS,EAAE;QAC5B,OAAOY,UAAU;;MAEnBF,SAAS,GAAG,IAAI,CAACnD,EAAE,CAACoD,CAAC,CAAC;MACtBA,CAAC,EAAE;;EAEP,CAAC;EAEDlF,WAAA,CAAAC,SAAA,CAAA2E,gBAAgB,GAAhB;IACE;IACA,IAAI,IAAI,CAACU,UAAU,CAACC,MAAM,KAAK,CAAC,EAAE;MAChC,OAAOlG,OAAA,CAAAC,cAAc;;IAEvB,IAAMkG,iBAAiB,GAAG,IAAI,CAACC,4BAA4B,EAAE;IAC7D,IAAMC,WAAW,GAAG,IAAI,CAACC,kCAAkC,EAAE;IAC7D,IAAMC,iBAAiB,GAAG,IAAI,CAACC,gCAAgC,EAAE;IAEjE,OAAO;MACLrD,QAAQ,EAAE,IAAI,CAACsD,uBAAuB,CAACN,iBAAiB,CAAC;MACzDO,gBAAgB,EAAEL,WAAW;MAC7BM,MAAM,EAAE,IAAI,CAACF,uBAAuB,CAACF,iBAAiB;KACvD;EACH,CAAC;EAED5F,WAAA,CAAAC,SAAA,CAAAgG,uBAAuB,GAAvB;IAAA,IAAArG,KAAA;IACE,IAAMsG,iBAAiB,GAAG,IAAI,CAACZ,UAAU;IACzC,IAAMa,uBAAuB,GAAG,IAAI,CAACC,qBAAqB;IAE1D,OAAO,IAAAvH,KAAA,CAAA0B,OAAG,EAAC2F,iBAAiB,EAAE,UAAC1D,QAAQ,EAAE6D,GAAG;MAC1C,IAAIA,GAAG,KAAK,CAAC,EAAE;QACb,OAAOhH,OAAA,CAAAC,cAAc;;MAEvB,OAAO;QACLkD,QAAQ,EAAE5C,KAAI,CAACkG,uBAAuB,CAACtD,QAAQ,CAAC;QAChDuD,gBAAgB,EAAEI,uBAAuB,CAACE,GAAG,CAAC;QAC9CL,MAAM,EAAEpG,KAAI,CAACkG,uBAAuB,CAACI,iBAAiB,CAACG,GAAG,GAAG,CAAC,CAAC;OAChE;IACH,CAAC,CAAC;EACJ,CAAC;EAEDrG,WAAA,CAAAC,SAAA,CAAA+E,gBAAgB,GAAhB;IAAA,IAAApF,KAAA;IACE,IAAM0G,WAAW,GAAG,IAAAzH,KAAA,CAAA0B,OAAG,EAAC,IAAI,CAAC0F,uBAAuB,EAAE,EAAE,UAACM,OAAO;MAC9D,OAAO3G,KAAI,CAACkF,yBAAyB,CAACyB,OAAO,CAAC;IAChD,CAAC,CAAC;IACF,OAAY,IAAA3H,SAAA,CAAA2B,OAAO,EAAC+F,WAAW,CAAC;EAClC,CAAC;EAEDtG,WAAA,CAAAC,SAAA,CAAA6E,yBAAyB,GAAzB,UAEEH,SAAqB;IAErB,IAAIA,SAAS,KAAKtF,OAAA,CAAAC,cAAc,EAAE;MAChC,OAAO,CAACf,eAAA,CAAAiI,GAAG,CAAC;;IAGd,IAAMC,UAAU,GACd9B,SAAS,CAACnC,QAAQ,GAAGmC,SAAS,CAACoB,gBAAgB,GAAG5G,WAAA,CAAAuH,EAAE,GAAG/B,SAAS,CAACqB,MAAM;IAEzE,OAAO,IAAI,CAAC3F,aAAa,CAACoG,UAAU,CAAC;EACvC,CAAC;EAED;EACA;EACAzG,WAAA,CAAAC,SAAA,CAAA+C,iBAAiB,GAAjB,UAEE2D,KAAa,EACbC,YAAsB;IAEtB,IAAI,CAAC,IAAI,CAAC/D,YAAY,CAAC8D,KAAK,EAAEpI,eAAA,CAAAiI,GAAG,CAAC,EAAE;MAClCI,YAAY,CAACC,IAAI,CAACF,KAAK,CAAC;;IAE1B,OAAOC,YAAY;EACrB,CAAC;EAED5G,WAAA,CAAAC,SAAA,CAAA6G,QAAQ,GAAR,UAA8BnG,OAAkB;IAC9C,IAAMgB,cAAc,GAAa,EAAE;IACnC,IAAIsC,OAAO,GAAG,IAAI,CAACnC,EAAE,CAAC,CAAC,CAAC;IACxB,OAAO,IAAI,CAACe,YAAY,CAACoB,OAAO,EAAEtD,OAAO,CAAC,KAAK,KAAK,EAAE;MACpDsD,OAAO,GAAG,IAAI,CAAClB,UAAU,EAAE;MAC3B,IAAI,CAACC,iBAAiB,CAACiB,OAAO,EAAEtC,cAAc,CAAC;;IAEjD;IACA,OAAO,IAAAhD,WAAA,CAAA4B,OAAS,EAACoB,cAAc,CAAC;EAClC,CAAC;EAED3B,WAAA,CAAAC,SAAA,CAAAQ,2BAA2B,GAA3B,UAEEsG,QAAkB,EAClBC,IAAW,EACXC,aAA4B,EAC5BC,YAAoB,EACpBC,cAAsB,EACtBC,cAAgE,EAChE/D,QAAkB;IAElB;IACA;EAAA,CACD;EAEDrD,WAAA,CAAAC,SAAA,CAAA0D,qBAAqB,GAArB,UAEEhD,OAAkB,EAClB8C,YAAoB;IAEpB,IAAM4D,aAAa,GAAa,IAAI,CAACC,yBAAyB,EAAE;IAChE,IAAMC,mBAAmB,GAAa,IAAAtI,OAAA,CAAAsB,OAAK,EAAC,IAAI,CAAC6F,qBAAqB,CAAC;IACvE,IAAM1C,WAAW,GAAQ;MACvB8D,SAAS,EAAEH,aAAa;MACxBI,eAAe,EAAEF,mBAAmB;MACpCG,OAAO,EAAE/G,OAAO;MAChBgH,iBAAiB,EAAElE;KACpB;IAED,OAAOC,WAAW;EACpB,CAAC;EACD1D,WAAA,CAAAC,SAAA,CAAAqH,yBAAyB,GAAzB;IAAA,IAAA1H,KAAA;IACE,OAAO,IAAAf,KAAA,CAAA0B,OAAG,EAAC,IAAI,CAAC+E,UAAU,EAAE,UAACsC,aAAa;MACxC,OAAAhI,KAAI,CAACkG,uBAAuB,CAAC8B,aAAa,CAAC;IAA3C,CAA2C,CAC5C;EACH,CAAC;EACH,OAAA5H,WAAC;AAAD,CAAC,EAzWD;AAAaX,OAAA,CAAAW,WAAA,GAAAA,WAAA;AA2Wb,SAAgBS,2BAA2BA,CAEzCsG,QAAkB,EAClBC,IAAW,EACXC,aAA4B,EAC5BC,YAAoB,EACpBC,cAAsB,EACtBC,cAAgE,EAChE/D,QAAkB;EAElB,IAAMwE,GAAG,GAAG,IAAI,CAACC,2BAA2B,CAACZ,YAAY,EAAEC,cAAc,CAAC;EAC1E,IAAIY,iBAAiB,GAAG,IAAI,CAAC3H,gBAAgB,CAACyH,GAAG,CAAC;EAClD,IAAIE,iBAAiB,KAAKxD,SAAS,EAAE;IACnC,IAAMyD,YAAY,GAAG,IAAI,CAACvF,mBAAmB,EAAE;IAC/C,IAAMwF,WAAW,GAAG,IAAI,CAACC,kBAAkB,EAAE,CAACF,YAAY,CAAC;IAC3D,IAAMG,MAAM,GACV,IAAIf,cAAc,CAACa,WAAW,EAAEd,cAAc,CAAC;IACjDY,iBAAiB,GAAGI,MAAM,CAACC,YAAY,EAAE;IACzC,IAAI,CAAChI,gBAAgB,CAACyH,GAAG,CAAC,GAAGE,iBAAiB;;EAGhD,IAAI5E,uBAAuB,GAAG4E,iBAAiB,CAACpB,KAAK;EACrD,IAAIvD,UAAU,GAAG2E,iBAAiB,CAACM,UAAU;EAC7C,IAAMC,WAAW,GAAGP,iBAAiB,CAACO,WAAW;EAEjD;EACA;EACA,IACE,IAAI,CAAChD,UAAU,CAACC,MAAM,KAAK,CAAC,IAC5B+C,WAAW,IACXnF,uBAAuB,KAAKoB,SAAS,EACrC;IACApB,uBAAuB,GAAG5E,eAAA,CAAAiI,GAAG;IAC7BpD,UAAU,GAAG,CAAC;;EAGhB;EACA;EACA,IAAID,uBAAuB,KAAKoB,SAAS,IAAInB,UAAU,KAAKmB,SAAS,EAAE;IACrE;;EAGF,IACE,IAAI,CAACrB,iCAAiC,CACpCC,uBAAuB,EACvBC,UAAU,EACVC,QAAQ,CACT,EACD;IACA;IACA;IACA;IACA,IAAI,CAACnC,uBAAuB,CAC1B6F,QAAQ,EACRC,IAAI,EACJC,aAAa,EACb9D,uBAAuB,CACxB;;AAEL;AA3DA9D,OAAA,CAAAoB,2BAAA,GAAAA,2BAAA"},"metadata":{},"sourceType":"script","externalDependencies":[]}